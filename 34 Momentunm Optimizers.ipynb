{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<img align=\"left\" width=\"110\"   src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\"> \n",
    "\n",
    "\n",
    "<h1 align=\"center\">Tools and Techniques for Data Science</h1>\n",
    "<h1 align=\"center\">Course: Deep Learning</h1>\n",
    "\n",
    "---\n",
    "<h3 align=\"right\">Muhammad Sheraz (Data Scientist)</h3>\n",
    "<h1 align=\"center\">Day34 (Momentunm Optimizers)</h1>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'><img  src='Images/types_gd.png'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawbacks of base optimizer:(GD, SGD, mini-batch GD)\n",
    "\n",
    "<img align='right' src='Images/gd.png'>\n",
    "\n",
    "- Gradient Descent uses the whole training data to update weight and bias. Suppose if we have millions of records then training becomes slow and computationally very expensive.\n",
    "\n",
    "- SGD solved the Gradient Descent problem by using only single records to updates parameters. But, still, SGD is slow to converge because it needs forward and backward propagation for every record. And the path to reach global minima becomes very noisy.\n",
    "\n",
    "- Mini-batch GD overcomes the SDG drawbacks by using a batch of records to update the parameter. Since it doesn't use entire records to update parameter, the path to reach global minima is not as smooth as Gradient Descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant Gradient:**\n",
    "- Gradient remains constant across iterations.\n",
    "- Often indicates a flat region in the optimization landscape.\n",
    "- In traditional gradient descent, leads to consistent updates in the parameter space.\n",
    "- In Momentum Optimization, results in steady momentum accumulation without abrupt changes.\n",
    "\n",
    "**High Curvature:**\n",
    "- Indicates rapid changes in the optimization landscape.\n",
    "- Typically found in regions with sharp peaks or valleys.\n",
    "- In traditional gradient descent, may result in slow convergence or oscillations around the optimum.\n",
    "- Momentum Optimization helps by smoothing out updates and efficiently navigating through regions with high curvature.\n",
    "\n",
    "**Noisy Gradient:**\n",
    "- Gradients exhibit significant fluctuations due to noisy data or stochasticity.\n",
    "- Often encountered in scenarios where data is incomplete or corrupted.\n",
    "- In traditional gradient descent, noisy gradients can lead to slow convergence or convergence to suboptimal solutions.\n",
    "- Momentum Optimization helps by averaging out the noise over time, resulting in smoother updates and faster convergence despite the noise.\n",
    "\n",
    "\n",
    "**Saddle Point:**\r\n",
    "- Saddle points are critical points in the optimization landscape where the gradient is zero but neither a minimum nor a maximum.\r\n",
    "- They are characterized by flat regions in some directions and steep regions in others.\r\n",
    "- In traditional gradient descent, convergence at saddle points can be slow due to the flat directions, causing the algorithm to get stuck.\r\n",
    "- Momentum Optimization helps in escaping saddle points by accumulating momentum in the steep directions, facilitating faster convergence.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex and Non-Convex Optimization\n",
    "\n",
    "\n",
    "\n",
    "**Convex Optimization:**\n",
    "- Objective function: Single global minimum.\n",
    "- All local minima are also global minima.\n",
    "- Gradient-based algorithms (e.g., gradient descent) guarantee convergence to the global minimum.\n",
    "- Examples: Linear programming, quadratic programming, least squares regression, support vector machines with linear kernels.\n",
    "\n",
    "**Non-Convex Optimization:**\n",
    "- Objective function: Multiple local minima, saddle points, and possibly global minima.\n",
    "- Convergence to global minimum is not guaranteed.\n",
    "- Gradient-based algorithms may get stuck in local minima or saddle points.\n",
    "- Exploration techniques (e.g., random restarts, simulated annealing) are often employed to find better solutions.\n",
    "- Examples: Neural network training, clustering algorithms (e.g., k-means), many real-world optimization problems.\n",
    "\n",
    "\n",
    "<img src='Images/connoncon.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read here For Detail Lecture**\n",
    "- <a href='https://pub.towardsai.net/gradient-descent-and-the-melody-of-optimization-algorithms-244830ea2516'>Link1</a>\n",
    "- <a href='https://towardsdatascience.com/learning-parameters-part-2-a190bef2d12'>Link2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Intution:** If I am repeatedly being asked to move in the same direction then I should probably gain some confidence and start taking bigger steps in that direction. Just as a ball gains momentum while rolling down a slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SGD with momentum\n",
    "\n",
    "<img align='right' src='Images/mom_int.png'> \n",
    "\n",
    "- It always works better than the normal Stochastic Gradient Descent Algorithm. \n",
    "\n",
    "- The problem with SGD is that while it tries to reach `minim`a because of the `high oscillation` we can’t `increase` the `learning rate`. So it takes time to \n",
    " converge. In this algorithm, we will be using `Exponentially Weighted Averages` to compute Gradient and used this Gradient to update parameter.\n",
    "\n",
    "- An equation to update weights and bias in SGD\n",
    "\n",
    "<div align='center'><img src='Images/f11.png'></div>\n",
    "\n",
    "- An equation to update weights and bias in SGD with momentum\n",
    "\n",
    "<div align='center'><img src='Images/mom_eq.png'></div>\n",
    "\n",
    "\n",
    "- In SGD with momentum, we have added momentum in a gradient function. By this I mean the present Gradient is dependent on its previous Gradient and so on. This accelerates SGD to converge faster and reduce the oscillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Momentum optimizer\n",
    "\n",
    "- Momentum optimizer helps accelerate gradient descent by adding a fraction of the update vector from the previous time step to the current update.\n",
    "- It reduces oscillations and helps the optimizer converge faster by smoothing out the updates.\n",
    "- This momentum allows the optimizer to continue in the same direction if previous gradients have been consistently pointing in that direction.\n",
    "- It's particularly effective in overcoming local minima or saddle points.\n",
    "- Momentum optimizer helps escape steep and narrow ravines in the loss landscape.\n",
    "- Overall, it improves the efficiency and speed of convergence during training neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Single benefit of  Momentum optimizer is `Speed`\n",
    "> - In `99%` cases, Momentum optimizer is faster than the normal Stochastic Gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role of alpha in momentum optimizer\n",
    "\n",
    "- In momentum optimizer, the parameter alpha (typically denoted as α) represents the momentum term.\r\n",
    "- Alpha controls the contribution of the previous update vector to the current update.\r\n",
    "- A higher value of alpha means more momentum, causing the optimizer to remember and build up speed in previous directions.\r\n",
    "- A lower value of alpha reduces the influence of past gradients, making the optimization process less persistent in previous directions.\r\n",
    "- The choice of alpha affects the trade-off between exploration and exploitation during optimization.\r\n",
    "- Typically, alpha values range between 0 and 1, with common values such as 0.9 or,0.5 0.99 used in practice.\r\n",
    "- Tuning alpha requires balancing between stability (avoiding oscillations) and efficiency (speeding up convergence).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When alpha is 0:\n",
    "  - The momentum term becomes ineffective.\n",
    "  - Each update is solely based on the current gradient without considering any past updates.\n",
    "  - Essentially equivalent to using vanilla gradient descent without momentum.\n",
    "  - No memory of past gradients, potentially leading to slower convergence.\n",
    "\n",
    "- When alpha is 1:\n",
    "  - The momentum term is fully utilized.\n",
    "  - The current update is entirely determined by the momentum term, ignoring the current gradient.\n",
    "  - Maintains constant velocity in previous directions, potentially leading to overshooting or instability.\n",
    "  - Persistence in previous directions might help escape local minima but can also lead to divergence.\n",
    "  - Setting alpha to 1 is generally not recommended due to instability risks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems of Momentum Optimizer\n",
    "\n",
    "- **Overshooting:**\n",
    "  - High momentum values can cause the optimizer to overshoot the minimum point, leading to oscillations or instability.\n",
    "- **Difficulty in Fine-Tuning:**\n",
    "  - Momentum might hinder fine-tuning in the later stages of training when approaching the minimum point.\n",
    "- **Parameter Sensitivity:**\n",
    "  - Momentum's effectiveness can vary significantly depending on the choice of learning rate and other hyperparameters.\n",
    "- **Memory Requirements:**\n",
    "  - Momentum requires additional memory to store previous update information, which could be a concern for memory-constrained environments.\n",
    "- **Dependency on Initial Conditions:**\n",
    "  - Momentum's behavior can be sensitive to the initial conditions, making it harder to predict its performance across different optimization tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Images/mom.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One typical drawback of the Momentum Optimizer is that the algorithm tends to oscillate at the minima (like a ball rolling down a v shaped valley) before stopping at the minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Interview Questions</h1>\n",
    "\n",
    "**1. What is Momentum Optimization in the context of machine learning and optimization algorithms?**\n",
    "\n",
    "   **Answer:** \n",
    "   Momentum Optimization is a technique used in optimization algorithms, particularly in stochastic gradient descent (SGD) variants, to accelerate convergence and escape local minima. It involves incorporating the notion of momentum, i.e., the accumulation of past gradients, to update the parameters of a model.\n",
    "\n",
    "**2. How does Momentum Optimization differ from traditional gradient descent?**\n",
    "\n",
    "   **Answer:** \n",
    "   In traditional gradient descent, the parameters are updated in the direction opposite to the gradient of the loss function with respect to those parameters. Momentum Optimization adds a momentum term that accelerates the updates by accumulating gradients over time, allowing for smoother and faster convergence, especially in regions with high curvature.\n",
    "\n",
    "**3. What is the formula for updating parameters using Momentum Optimization?**\n",
    "\n",
    "   **Answer:** \n",
    "   The formula for updating parameters using Momentum Optimization is:\n",
    "\n",
    "   <div align='center'><img src='Images/mom_eq.png'></div>\n",
    "\n",
    "  \n",
    "**4. What is the purpose of the momentum term in Momentum Optimization?**\n",
    "\n",
    "   **Answer:** \n",
    "   The momentum term serves to accelerate convergence by accumulating gradients from past updates. It smooths out the updates by incorporating information about the direction of previous gradients, which helps to navigate through flat regions or saddle points more efficiently and escape local minima.\n",
    "\n",
    "**5. How do you choose the value of the momentum parameter `beta` in Momentum Optimization?**\n",
    "\n",
    "   **Answer:** \n",
    "   The choice of the momentum parameter depends on the characteristics of the optimization problem and the data. Typically, values for `beta` range between 0 and 1, with common choices being around 0.9. Higher values of `beta` result in stronger momentum and faster convergence, but too high a value may lead to oscillations or overshooting.\n",
    "\n",
    "**6. Can Momentum Optimization be combined with other optimization techniques?**\n",
    "\n",
    "   **Answer:** \n",
    "   Yes, Momentum Optimization can be combined with techniques like learning rate schedules (e.g., learning rate decay) and adaptive learning rate methods (e.g., Adam, RMSprop) to further improve convergence and stability.\n",
    "\n",
    "**7. What are the advantages of using Momentum Optimization?**\n",
    "\n",
    "   **Answer:** \n",
    "   - Momentum Optimization accelerates convergence, especially in the presence of noisy or sparse gradients.\n",
    "   - It helps to escape local minima and plateaus more effectively compared to traditional gradient descent.\n",
    "   - Momentum can act as a form of inertia, smoothing out updates and reducing oscillations during optimization.\n",
    "\n",
    "**8. Are there any limitations or drawbacks to using Momentum Optimization?**\n",
    "\n",
    "   **Answer:** \n",
    "   - Momentum Optimization may overshoot or oscillate around the optimal solution if the momentum parameter is too high.\n",
    "   - It introduces an additional hyperparameter `beta` that needs to be tuned.\n",
    "   - Momentum may cause the algorithm to converge too quickly, skipping over potentially valuable regions of the parameter space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
