{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<img align=\"left\" width=\"110\"   src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\"> \n",
    "\n",
    "\n",
    "<h1 align=\"center\">Tools and Techniques for Data Science</h1>\n",
    "<h1 align=\"center\">Course: Deep Learning</h1>\n",
    "\n",
    "---\n",
    "<h3 align=\"right\">Muhammad Sheraz (Data Scientist)</h3>\n",
    "<h1 align=\"center\">Day34 (Momentunm Optimizers)</h1>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawbacks of base optimizer:(GD, SGD, mini-batch GD)\n",
    "\n",
    "<img align='right' src='Images/mom_int.png'>\n",
    "- Gradient Descent uses the whole training data to update weight and bias. Suppose if we have millions of records then training becomes slow and computationally very expensive.\n",
    "\n",
    "- SGD solved the Gradient Descent problem by using only single records to updates parameters. But, still, SGD is slow to converge because it needs forward and backward propagation for every record. And the path to reach global minima becomes very noisy.\n",
    "\n",
    "- Mini-batch GD overcomes the SDG drawbacks by using a batch of records to update the parameter. Since it doesn't use entire records to update parameter, the path to reach global minima is not as smooth as Gradient Descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SGD with momentum\n",
    "\n",
    "<img align='right' src='Images/mom_int.png'>\n",
    "\n",
    "- It always works better than the normal Stochastic Gradient Descent Algorithm. \n",
    "\n",
    "- The problem with SGD is that while it tries to reach `minim`a because of the `high oscillation` we can’t `increase` the `learning rate`. So it takes time to \n",
    " converge. In this algorithm, we will be using `Exponentially Weighted Averages` to compute Gradient and used this Gradient to update parameter.\n",
    "\n",
    "- An equation to update weights and bias in SGD\n",
    "\n",
    "<div align='center'><img src='Images/f11.png'></div>\n",
    "\n",
    "- An equation to update weights and bias in SGD with momentum\n",
    "\n",
    "<div align='center'><img src='Images/mom_eq.png'></div>\n",
    "\n",
    "<img align='right' src='Images/mom_int.png'> \n",
    "\n",
    "- In SGD with momentum, we have added momentum in a gradient function. By this I mean the present Gradient is dependent on its previous Gradient and so on. This accelerates SGD to converge faster and reduce the oscillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Momentum optimizer\n",
    "\n",
    "- Momentum optimizer helps accelerate gradient descent by adding a fraction of the update vector from the previous time step to the current update.\n",
    "- It reduces oscillations and helps the optimizer converge faster by smoothing out the updates.\n",
    "- This momentum allows the optimizer to continue in the same direction if previous gradients have been consistently pointing in that direction.\n",
    "- It's particularly effective in overcoming local minima or saddle points.\n",
    "- Momentum optimizer helps escape steep and narrow ravines in the loss landscape.\n",
    "- Overall, it improves the efficiency and speed of convergence during training neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Single benefit of  Momentum optimizer is `Speed`\n",
    "> - In `99%` cases, Momentum optimizer is faster than the normal Stochastic Gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role of alpha in momentum optimizer\n",
    "\n",
    "- In momentum optimizer, the parameter alpha (typically denoted as α) represents the momentum term.\r\n",
    "- Alpha controls the contribution of the previous update vector to the current update.\r\n",
    "- A higher value of alpha means more momentum, causing the optimizer to remember and build up speed in previous directions.\r\n",
    "- A lower value of alpha reduces the influence of past gradients, making the optimization process less persistent in previous directions.\r\n",
    "- The choice of alpha affects the trade-off between exploration and exploitation during optimization.\r\n",
    "- Typically, alpha values range between 0 and 1, with common values such as 0.9 or,0.5 0.99 used in practice.\r\n",
    "- Tuning alpha requires balancing between stability (avoiding oscillations) and efficiency (speeding up convergence).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When alpha is 0:\n",
    "  - The momentum term becomes ineffective.\n",
    "  - Each update is solely based on the current gradient without considering any past updates.\n",
    "  - Essentially equivalent to using vanilla gradient descent without momentum.\n",
    "  - No memory of past gradients, potentially leading to slower convergence.\n",
    "\n",
    "- When alpha is 1:\n",
    "  - The momentum term is fully utilized.\n",
    "  - The current update is entirely determined by the momentum term, ignoring the current gradient.\n",
    "  - Maintains constant velocity in previous directions, potentially leading to overshooting or instability.\n",
    "  - Persistence in previous directions might help escape local minima but can also lead to divergence.\n",
    "  - Setting alpha to 1 is generally not recommended due to instability risks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems of Momentum Optimizer\n",
    "\n",
    "- **Overshooting:**\n",
    "  - High momentum values can cause the optimizer to overshoot the minimum point, leading to oscillations or instability.\n",
    "- **Difficulty in Fine-Tuning:**\n",
    "  - Momentum might hinder fine-tuning in the later stages of training when approaching the minimum point.\n",
    "- **Parameter Sensitivity:**\n",
    "  - Momentum's effectiveness can vary significantly depending on the choice of learning rate and other hyperparameters.\n",
    "- **Memory Requirements:**\n",
    "  - Momentum requires additional memory to store previous update information, which could be a concern for memory-constrained environments.\n",
    "- **Dependency on Initial Conditions:**\n",
    "  - Momentum's behavior can be sensitive to the initial conditions, making it harder to predict its performance across different optimization tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
