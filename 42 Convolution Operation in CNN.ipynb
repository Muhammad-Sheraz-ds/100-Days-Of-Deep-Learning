{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518eeb6b-4a65-4cff-bbcf-db6e346f9ef3",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<img align=\"left\" width=\"110\"   src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\"> \n",
    "\n",
    "\n",
    "<h1 align=\"center\">Tools and Techniques for Data Science</h1>\n",
    "<h1 align=\"center\">Course: Deep Learning</h1>\n",
    "\n",
    "---\n",
    "<h3 align=\"right\">Muhammad Sheraz (Data Scientist)</h3>\n",
    "<h1 align=\"center\">Day 42 (Convolutional Operations)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c5788-e309-4d24-a9ef-bcb2ec68c4e1",
   "metadata": {},
   "source": [
    "<img src='Images/cinv_layer.ppm'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4e53c-12b1-4c85-b206-0db10bf01b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa970b74-587e-444d-af4a-61643ece3893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa58b75-b391-4413-b5aa-f708aa453196",
   "metadata": {},
   "source": [
    "<a href='https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939'>Link 1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc1812-5c79-4b7c-b727-5f7707c03e90",
   "metadata": {},
   "source": [
    "# Convolutional Operations in Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## Introduction\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models particularly effective for tasks involving images and other structured data. Central to CNNs are convolutional operations, which play a key role in extracting features from input data.\n",
    "\n",
    "## Convolutional Operation\n",
    "- **Convolution**: \n",
    "  - A mathematical operation that combines two functions to produce a third function.\n",
    "  - In CNNs, convolution is applied between the input data (e.g., an image) and a filter (also known as a kernel or a feature detector).\n",
    "- **Filter**:\n",
    "  - A small matrix used for feature extraction.\n",
    "  - Typically has learnable parameters that are adjusted during the training process.\n",
    "- **Stride**:\n",
    "  - The number of pixels by which the filter is moved across the input.\n",
    "  - Determines the amount of overlap between successive regions.\n",
    "- **Padding**:\n",
    "  - Adding extra border pixels to the input image.\n",
    "  - Helps to preserve spatial dimensions and information.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab8dd3-48f3-4238-a4dc-32c9093f1526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b37660-e03e-46a5-b711-fedc8b75f1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "376220b6-02d5-4e93-a98a-72872f6a54fb",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "- **Convolutional Layer**:\n",
    "  - The primary building block of a CNN.\n",
    "  - Comprises multiple filters applied to the input data.\n",
    "  - Produces feature maps capturing different aspects of the input.\n",
    "- **Feature Map**:\n",
    "  - The output of applying filters to the input.\n",
    "  - Represents the presence of particular features in the input data.\n",
    "  \n",
    "## Convolutional Operation Example\n",
    "- **Example**:\n",
    "  - Consider a grayscale image with dimensions 5x5 and a 3x3 filter.\n",
    "  - Apply the filter with a stride of 1 and no padding.\n",
    "  - Output feature map will have dimensions 3x3.\n",
    "- **Formula**:\n",
    "  - Output dimension = ((input dimension - filter dimension + 2 * padding) / stride) + 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29add4dc-3e62-4922-90bd-cc024357f497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53ccc201-c332-4bd9-b702-fc5ce3420054",
   "metadata": {},
   "source": [
    "> If we have an activation map of size W x W x D, a pooling kernel of spatial size F, and stride S, then the size of output volume can be determined by the following formula:\n",
    "\n",
    "<div height='100px' width='100px' align='center'><img src='Images/conv_layer_f2.PNG'></div>\n",
    "\n",
    "> This will yield an output volume of size Wout x Wout x D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f3377-6bbf-446e-8102-3120e2607617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5200a857-1805-40d4-a5a5-90c304e18374",
   "metadata": {},
   "source": [
    "> If we have an input of size W x W x D and Dout number of kernels with a spatial size of F with stride S and amount of padding P, then the size of output volume can be determined by the following formula:\n",
    "\n",
    "<div align='center'><img src='Images/conv_layer_f1.PNG'></div>\n",
    "\n",
    "> This will yield an output volume of size Wout x Wout x Dout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d47379-3f36-40aa-b1c0-dfcd9c580204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd2492-222f-47fc-90dd-5280691f8d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d38bf2-ac88-4fc8-bfd1-6ce5b116eaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a126e-85fa-4620-b142-8a112154f90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cae8ae-56e4-4c8a-ab84-04b7e5a4b3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572c7f8-5aa3-4088-8c93-8c4b4744c0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b81291-3364-431c-acb4-f602e7d5c386",
   "metadata": {},
   "source": [
    "## Applications\n",
    "- **Image Processing**:\n",
    "  - Edge detection, feature extraction, etc.\n",
    "- **Computer Vision**:\n",
    "  - Object detection, image classification, semantic segmentation, etc.\n",
    "- **Natural Language Processing (NLP)**:\n",
    "  - Text classification, sentiment analysis, etc.\n",
    "\n",
    "## Conclusion\n",
    "Convolutional operations form the foundation of Convolutional Neural Networks, enabling them to learn hierarchical representations of complex data such as images and text. Understanding how convolutions work is crucial for mastering CNNs and their applications in various domains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530dc52-9dd5-4888-a6e1-5bfdf22cdeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331621b-b986-43f8-a6f4-f099c995ab84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56bd9d1c",
   "metadata": {},
   "source": [
    "## Residual Networks (ResNets)\n",
    "- https://towardsdatascience.com/residual-networks-resnets-cb474c7c834a\n",
    "\n",
    "\n",
    "## Understanding Inception: Simplifying the Network Architecture\n",
    "\n",
    "- https://medium.com/swlh/understanding-inception-simplifying-the-network-architecture-54cd31d38949\n",
    "\n",
    "\n",
    "## Understanding Architecture Of Inception Network & Applying It To A Real-World Dataset\n",
    "- https://gghantiwala.medium.com/understanding-the-architecture-of-the-inception-network-and-applying-it-to-a-real-world-dataset-169874795540\n",
    "\n",
    "## Depth-wise Convolution and Depth-wise Separable Convolution\n",
    "\n",
    "- https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec\n",
    "\n",
    "##  spatial separable convolutions, and depthwise separable convolutions.\n",
    "\n",
    "https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728\n",
    "## Understanding Depthwise Separable Convolutions and the efficiency of MobileNets\n",
    "\n",
    "- https://towardsdatascience.com/understanding-depthwise-separable-convolutions-and-the-efficiency-of-mobilenets-6de3d6b62503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ba130-bd2f-4f65-b671-2799ceffa0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
